{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "NN_GOOGLE_COLAB.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DariuszKobiela/DigitPredictorAI/blob/master/NN_GOOGLE_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrxVRpwAl5eq",
        "colab_type": "code",
        "outputId": "f9df5f93-8795-4a6a-fd5b-7d6deabb773d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NikDioaYqPom",
        "colab_type": "code",
        "outputId": "47d7ff43-52a6-4b88-9539-59fe9762b01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuAmbJ5al0ro",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7z9W9Ual0rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.metrics import Accuracy, Recall, Precision\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "\n",
        "\n",
        "def load_data_for_NN(root_directory):\n",
        "    mnist_train = pd.read_csv(root_directory+\"data/mnist_train.csv\")\n",
        "    mnist_test = pd.read_csv(root_directory+\"data/mnist_test.csv\")\n",
        "    y_train = mnist_train.label.values\n",
        "    y_test = mnist_test.label.values\n",
        "    x_train = mnist_train.values[:, 1:]\n",
        "    x_test = mnist_test.values[:, 1:]\n",
        "    # Standardization\n",
        "    x_train = np.array([(x - x.mean()) / x.std() for x in x_train])\n",
        "    x_test = np.array([(x - x.mean()) / x.std() for x in x_test])\n",
        "    x_train = x_train.astype('float32').reshape(-1, 28, 28, 1)\n",
        "    x_test = x_test.astype('float32').reshape(-1, 28, 28, 1)\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "\n",
        "def load_images(root_directory):\n",
        "    mnist = pd.read_csv(root_directory+\"data/mnist_test.csv\")\n",
        "    y = mnist.label.values\n",
        "    x = mnist.values[:, 1:].astype('float32').reshape(-1, 28, 28)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def model_DNN():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=[28, 28, 1]))\n",
        "    model.add(Dense(512))\n",
        "    model.add(Dense(128))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def model_CNN():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=[28, 28, 1]))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_checkpoint_path(model_name, root_directory):\n",
        "    checkpoint_path = root_directory + model_name + \"_training/cp.ckpt\"\n",
        "    return checkpoint_path\n",
        "\n",
        "\n",
        "def fit_model(model, model_name, x_train, y_train, batch_size, num_epoch, root_directory):\n",
        "    checkpoint_path = get_checkpoint_path(model_name, root_directory)\n",
        "    cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                  save_weights_only=True,\n",
        "                                  verbose=1,\n",
        "                                  monitor=\"loss\")\n",
        "    model_log = model.fit(x_train, y_train, batch_size=batch_size, validation_split=0.3, epochs=num_epoch,\n",
        "                          verbose=1, callbacks=[cp_callback])\n",
        "    return model_log, model\n",
        "\n",
        "\n",
        "def validate(model, x_train, y_train, x_test, y_test):\n",
        "    score = model.evaluate(x_train, y_train, verbose=0)\n",
        "    print('Train loss:', score[0], end=\", \")\n",
        "    print('Train accuracy:', score[1])\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0], end=\", \")\n",
        "    print('Test accuracy:', score[1])\n",
        "    print(model.summary())\n",
        "\n",
        "\n",
        "def save_model_plot(model, model_name, root_directory):\n",
        "    plot_model(model, to_file=root_directory+\"images/\" + model_name + '_architecture.png', show_shapes=True, show_layer_names=False)\n",
        "\n",
        "\n",
        "def plot_metric(model_log, metric_name, model_name, root_directory):\n",
        "    fig = plt.figure()\n",
        "    fig.set_size_inches(6, 4)\n",
        "    plt.plot(model_log.history[metric_name])\n",
        "    plt.plot(model_log.history['val_' + metric_name])\n",
        "    plt.title('model' + model_name + \" - \" + metric_name)\n",
        "    plt.ylabel(metric_name)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='lower right')\n",
        "    plt.savefig(root_directory + \"images/\" + model_name + '_' + metric_name + '.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI0HemP7l0ry",
        "colab_type": "text"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJCbqfAsl0r0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7381f855-00fe-439b-e751-65726c6d0ad8"
      },
      "source": [
        "batch_size = 128\n",
        "num_epoch = 6\n",
        "root_directory = \"/content/drive/My Drive/COLAB/\"\n",
        "\n",
        "print(\"--------------------------------\")\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_data_for_NN(root_directory)\n",
        "\n",
        "for model_name, model in [(\"CNN\", model_CNN()), (\"DNN\", model_DNN())]:\n",
        "    model_log, model = fit_model(model, model_name, x_train, y_train, batch_size, num_epoch, root_directory)\n",
        "    validate(model, x_train, y_train, x_test, y_test)\n",
        "    save_model_plot(model, model_name, root_directory)\n",
        "    for metric_name in ['accuracy', 'loss']:\n",
        "        plot_metric(model_log, metric_name, model_name, root_directory)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------\n",
            "Epoch 1/6\n",
            "328/329 [============================>.] - ETA: 0s - loss: 2.2870 - acc: 0.1388\n",
            "Epoch 00001: saving model to /content/drive/My Drive/COLAB/CNN_training/cp.ckpt\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.2867 - acc: 0.1389 - val_loss: 2.1505 - val_acc: 0.2903\n",
            "Epoch 2/6\n",
            "321/329 [============================>.] - ETA: 0s - loss: 2.1381 - acc: 0.2451\n",
            "Epoch 00002: saving model to /content/drive/My Drive/COLAB/CNN_training/cp.ckpt\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 2.1368 - acc: 0.2461 - val_loss: 1.9983 - val_acc: 0.6157\n",
            "Epoch 3/6\n",
            "328/329 [============================>.] - ETA: 0s - loss: 2.0022 - acc: 0.3630\n",
            "Epoch 00003: saving model to /content/drive/My Drive/COLAB/CNN_training/cp.ckpt\n",
            "329/329 [==============================] - 2s 8ms/step - loss: 2.0023 - acc: 0.3630 - val_loss: 1.8434 - val_acc: 0.7193\n",
            "Epoch 4/6\n",
            "325/329 [============================>.] - ETA: 0s - loss: 1.8648 - acc: 0.4489\n",
            "Epoch 00004: saving model to /content/drive/My Drive/COLAB/CNN_training/cp.ckpt\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.8634 - acc: 0.4496 - val_loss: 1.6773 - val_acc: 0.7594\n",
            "Epoch 5/6\n",
            "320/329 [============================>.] - ETA: 0s - loss: 1.7211 - acc: 0.5131\n",
            "Epoch 00005: saving model to /content/drive/My Drive/COLAB/CNN_training/cp.ckpt\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.7199 - acc: 0.5133 - val_loss: 1.5015 - val_acc: 0.7874\n",
            "Epoch 6/6\n",
            "323/329 [============================>.] - ETA: 0s - loss: 1.5746 - acc: 0.5604\n",
            "Epoch 00006: saving model to /content/drive/My Drive/COLAB/CNN_training/cp.ckpt\n",
            "329/329 [==============================] - 2s 7ms/step - loss: 1.5724 - acc: 0.5612 - val_loss: 1.3301 - val_acc: 0.8061\n",
            "Train loss: 1.3414132595062256, Train accuracy: 0.794866681098938\n",
            "Test loss: 1.328848123550415, Test accuracy: 0.8044999837875366\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9a9b1d61bd1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msave_model_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mplot_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-dfc2e6811eca>\u001b[0m in \u001b[0;36mplot_metric\u001b[0;34m(model_log, metric_name, model_name, root_directory)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" - \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WxwFPpnpS_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_directory = \"/content/drive/My Drive/COLAB/\"\n",
        "\n",
        "x_train, y_train, x_test, y_test = load_data_for_NN(root_directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Kj85qBNl0r4",
        "colab_type": "text"
      },
      "source": [
        "# LOADING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdkGtyPll0r5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_name = \"CNN\"\n",
        "# checkpoint_path = get_checkpoint_path(model_name, root_directory)\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "#\n",
        "# model = model_CNN()\n",
        "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "# model.load_weights(latest)\n",
        "\n",
        "# print(x_test[0].shape)\n",
        "#     # print(model.predict(x_test[0].reshape(1, 28, 28, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}